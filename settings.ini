[Settings]
LogLevel = 
device =

[Database]
collection_name=collections
persist_path =

[Models]
embedding_model=models/multilingual-e5-large
llm_model=models/Llama-3.2-3B-Instruct
ranker_model=models/all-MiniLM-L6-v2

[Documents]
tika_url=http://localhost:9998/tika
unstructured_url=http://localhost:8000/general/v0/general
remove_empty_lines=true
remove_extra_whitespaces=true
remove_repeated_substrings=true
split_by=sentence
split_length=5
split_overlap=2
split_threshold=5

; Defines how to handle documents with same ID in a document store:
; - overwrite: replaces an existing document with the same ID with a new document
; - skip: skips the new document and doesn't add it to the document store
; - fail: raises an error if a document with same ID already exists
; - none: relies on document store settings
policy=overwrite

[LLM]
task=text-generation
max_new_tokens=500
temperature=0.1
top_k=5
top_p=0.95
repetition_penalty=1.15
return_full_text=false

; Choose between several indexing pipelines:
;   haystack     - Utilizes haystack-ai converters to extract text from
;                  documents and images. Not all files types supported so
;                  refer to haystack-ai documentation for what files are
;                  supported. No docker container required. File types
;                  currently implemented: PDF, CSV, TXT.
;   tika         - Utilizes the Apache Tika docker container to extract text
;                  from documents and images. This requires running the
;                  apache/tika docker container before running the RAG
;                  application.
;   unstructured - Utilizes the Unstructured IO docker container to extract
;                  text from documents and images. This requires running the
;                  unstructured-api docker container before running the RAG
;                  application.
[Indexing Pipeline]
pipeline=tika
  
[Prompts]
template = You are a helpful assistant. Answer the question as detailed as possible from
 the provided context and conversation history. If the answer is not in the
 provided context, just say, 'answer is not available in the context'.
 
 Conversation history:
 {%% for memory in memories %%}
     {{ memory.content }}
 {%% endfor %%}
 
 Context:
 {%% for document in documents %%}
     {{ document.content }}
 {%% endfor %%}
 
 Question:
 {{ question }}
 
 Answer: